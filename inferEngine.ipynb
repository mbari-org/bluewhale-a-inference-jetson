{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "#!{sys.executable} -m pip install pycuda\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import pycuda.autoinit\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/blueA_VGG16.engine\", \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"blueAPCENBLEDval2048spec/bat/20150808T085348.13641700.13691700.sel.57.ch01.spectrogram.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150528\n"
     ]
    }
   ],
   "source": [
    "width, height = 224, 224\n",
    "binding_shape = (width, height)\n",
    "print(trt.volume(engine.get_binding_shape(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set host input by transorming spectrogram to fit for cuda interfacing:\n",
    "\n",
    "init. dim   |    reshape    |   transpose   |   flatten\n",
    "____________|_______________|_______________|______________\n",
    "(299,299,3) |-> (224,224,3) |-> (3,224,224) | -> (150528,)\n",
    "\n",
    "NOTE: pixel weights must be float32\n",
    "\n",
    "'''\n",
    "h_input = np.reshape(np.transpose(cv2.resize(im,binding_shape)),\n",
    "                     trt.volume(engine.get_binding_shape(0))).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Determine dimensions and create page-locked memory buffers (i.e. won't be swapped to disk) \n",
    "to hold host inputs/outputs.\n",
    "'''\n",
    "#h_input = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(0)), dtype=np.float32)\n",
    "h_output = cuda.pagelocked_empty(trt.volume(engine.get_binding_shape(1)), dtype=np.float32)\n",
    "# Allocate device memory for inputs and outputs.\n",
    "d_input = cuda.mem_alloc(h_input.nbytes)\n",
    "d_output = cuda.mem_alloc(h_output.nbytes)\n",
    "# Create a stream in which to copy inputs/outputs and run inference.\n",
    "stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7762563  0.22374369]\n"
     ]
    }
   ],
   "source": [
    "with engine.create_execution_context() as context:\n",
    "    # Transfer input data to the GPU.\n",
    "    cuda.memcpy_htod_async(d_input, h_input, stream)\n",
    "    # Run inference.\n",
    "    context.execute_async(bindings=[int(d_input), int(d_output)], stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return the host output. \n",
    "print(h_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blueA_infer_kernel",
   "language": "python",
   "name": "bluea_infer_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
